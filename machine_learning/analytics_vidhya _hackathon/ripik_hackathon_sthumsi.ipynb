{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:37.594377Z",
     "start_time": "2023-12-02T20:20:37.453693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "path_to_train_images = './data/train/images/'\n",
    "path_to_train_csv = ('./data/train/train.csv')\n",
    "\n",
    "path_to_test_images = './data/test/images/'\n",
    "path_to_test_csv = './data/test/test.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:37.595088Z",
     "start_time": "2023-12-02T20:20:37.482166Z"
    }
   },
   "id": "5e2f16177e5c180"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "#importing necessary packages\n",
    "import keras\n",
    "import os\n",
    "import shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, GlobalAveragePooling1D, GlobalAveragePooling2D, Flatten, BatchNormalization, Dense\n",
    "\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import optimizers\n",
    "from keras.optimizers import *\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:37.595605Z",
     "start_time": "2023-12-02T20:20:37.508449Z"
    }
   },
   "id": "adb22b1c7b2237f5"
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "train_images = [f for f in listdir(path_to_train_images) if isfile(join(path_to_train_images, f))]\n",
    "test_images = [f for f in listdir(path_to_test_images) if isfile(join(path_to_test_images,f))]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:37.598241Z",
     "start_time": "2023-12-02T20:20:37.529457Z"
    }
   },
   "id": "f87f9ed74d31a359"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class1\n"
     ]
    }
   ],
   "source": [
    "#print(train_images[0])\n",
    "print(test_images[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:37.650433Z",
     "start_time": "2023-12-02T20:20:37.544143Z"
    }
   },
   "id": "d75f04c487e985ef"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "import csv\n",
    "def make_list_from_csv(path_to_csv):\n",
    "    with open(path_to_csv,'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        csv_contents = []\n",
    "        for line in csv_reader:\n",
    "            csv_contents.append(line)\n",
    "        return csv_contents\n",
    "\n",
    "train_csv_contents = make_list_from_csv(path_to_train_csv)\n",
    "test_csv_contents = make_list_from_csv(path_to_test_csv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:37.661586Z",
     "start_time": "2023-12-02T20:20:37.563908Z"
    }
   },
   "id": "45446fc3038965a4"
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_id', 'filename', 'label']\n",
      "['image_id', 'filename']\n"
     ]
    }
   ],
   "source": [
    "print(train_csv_contents[0])\n",
    "print(test_csv_contents[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:37.798944Z",
     "start_time": "2023-12-02T20:20:37.607873Z"
    }
   },
   "id": "e4d133f28cfd70ad"
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1.jpg', '2']\n",
      "['7201', '7201.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(train_csv_contents[1])\n",
    "print(test_csv_contents[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:37.800371Z",
     "start_time": "2023-12-02T20:20:37.648159Z"
    }
   },
   "id": "727b96d31aa76a60"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7200', '7200.jpg', '2']\n",
      "['12000', '12000.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(train_csv_contents[-1])\n",
    "print(test_csv_contents[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:37.828784Z",
     "start_time": "2023-12-02T20:20:37.666490Z"
    }
   },
   "id": "c1d550f8a9fb630d"
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n"
     ]
    }
   ],
   "source": [
    "#I want to group the images by the class they belong to. Then, I will write the images into subdirectories in the class they belong to. This will happen only in the training set. We do not know the classes in the test set.\n",
    "def make_groupings_per_class(csv_contents,istestdir=False):\n",
    "    insurance_claim_types = []\n",
    "    distributions = {}\n",
    "    csv_contents_sans_label = csv_contents[1:]\n",
    "    for c in csv_contents_sans_label :\n",
    "        #here, i want to make a small adjustment to the test set. The given test set does not have the ytest column that would help me to evaluate my model. instead, i have to rely on the predict function to blind-predict what classes will be without knowing the true labels. Therefore, it doesn't matter what class the test set belongs to, I will merge all of them into one directory just to create the image generator. \n",
    "        if istestdir:\n",
    "            insur_type=1\n",
    "        else:\n",
    "            insur_type = int(c[-1])\n",
    "        current_img_name = c[1]\n",
    "        insurance_claim_types.append(insur_type)\n",
    "        if insur_type in distributions.keys():\n",
    "            existing_list = distributions[insur_type]\n",
    "            existing_list.append(current_img_name)\n",
    "        else:\n",
    "            distributions[insur_type] = [current_img_name]\n",
    "    return sorted(set(insurance_claim_types)), distributions\n",
    "train_claim_classes, train_image_distributions = make_groupings_per_class(train_csv_contents)\n",
    "test_claim_classes,test_image_distributions = make_groupings_per_class(test_csv_contents,istestdir=True)\n",
    "\"\"\"\n",
    "class 1- crack, 2 - scratch, 3 - flat tire, 4 - dent, 5 - glass shatter, 6 - lamp broken\n",
    "\"\"\"\n",
    "#print(train_claim_classes)\n",
    "print(len(test_image_distributions[1]))\n",
    "\n",
    "#CREATING SUBDIRECTORIES FOR EACH OF THE CLASSES\n",
    "def refile_images_per_classes(image_dictionary,istestdir=False):\n",
    "    for classname,list_of_images in image_dictionary.items():\n",
    "        for l in list_of_images:\n",
    "            try:\n",
    "                if istestdir:\n",
    "                    shutil.copy(path_to_test_images+l, './data/test/images/class'+str(classname))\n",
    "                else:\n",
    "                    shutil.copy(path_to_train_images+l, './data/train/images/class'+str(classname))\n",
    "                os.remove(path_to_test_images+l)\n",
    "                os.remove(path_to_train_images+l)\n",
    "            except FileNotFoundError:\n",
    "                print('already moved the file, please check respective class sub directory')\n",
    "        \n",
    "#refile_images_per_classes(train_image_distributions)\n",
    "#refile_images_per_classes(test_image_distributions,istestdir=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:22:43.584016Z",
     "start_time": "2023-12-02T20:22:43.427506Z"
    }
   },
   "id": "47dcdcf9d6d1fa6a"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7200 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "#preparing for preprocessing and transormation for training\n",
    "rescale = 1./255\n",
    "target_size = (100,100)\n",
    "batch_size = 100\n",
    "class_mode = 'categorical'\n",
    "\n",
    "train_data_generator = ImageDataGenerator(rescale=rescale,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    path_to_train_images,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:45.545662Z",
     "start_time": "2023-12-02T20:20:43.845379Z"
    }
   },
   "id": "9f22879f5a0abd55"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:20:45.547171Z",
     "start_time": "2023-12-02T20:20:45.513442Z"
    }
   },
   "id": "f6eb5672ca7820b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
